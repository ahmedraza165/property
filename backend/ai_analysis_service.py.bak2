import logging
import time
import json
from typing import Dict, Optional, List, Tuple
from datetime import datetime
import requests
import base64
from io import BytesIO

logger = logging.getLogger(__name__)


class AIAnalysisService:
    """
    Service for AI-based property analysis using computer vision models.
    Supports road condition detection and power line detection from imagery.
    """

    def __init__(self):
        self.session = self._create_session()
        self.model_version = "v1.0"

        # Initialize AI models (lazy loading)
        self._road_model = None
        self._powerline_model = None
        self._development_model = None

        # Rate limiting
        self._last_api_call = 0
        self._api_call_delay = 0.5  # 500ms between calls
        self._retry_delay = 2.0  # 2s delay on rate limit

    def _create_session(self) -> requests.Session:
        """Create a requests session with retry logic."""
        session = requests.Session()
        session.headers.update({
            'User-Agent': 'PropertyAnalysis-AI/1.0'
        })
        return session

    def _call_openai_with_retry(self, url: str, headers: Dict, payload: Dict, max_retries: int = 3) -> Optional[Dict]:
        """
        Call OpenAI API with rate limiting and retry logic.

        Args:
            url: API endpoint
            headers: Request headers
            payload: Request payload
            max_retries: Maximum number of retries

        Returns:
            API response dict or None
        """
        for attempt in range(max_retries):
            try:
                # Rate limiting - wait if needed
                current_time = time.time()
                time_since_last = current_time - self._last_api_call
                if time_since_last < self._api_call_delay:
                    sleep_time = self._api_call_delay - time_since_last
                    logger.debug(f"Rate limiting: sleeping {sleep_time:.2f}s")
                    time.sleep(sleep_time)

                # Make API call
                response = self.session.post(url, headers=headers, json=payload, timeout=60)
                self._last_api_call = time.time()

                # Handle rate limiting
                if response.status_code == 429:
                    retry_after = int(response.headers.get('Retry-After', self._retry_delay))
                    logger.warning(f"Rate limited (429). Waiting {retry_after}s before retry {attempt + 1}/{max_retries}")
                    time.sleep(retry_after)
                    continue

                response.raise_for_status()
                return response.json()

            except requests.exceptions.HTTPError as e:
                if e.response.status_code == 429 and attempt < max_retries - 1:
                    logger.warning(f"Rate limit retry {attempt + 1}/{max_retries}")
                    time.sleep(self._retry_delay * (attempt + 1))  # Exponential backoff
                    continue
                logger.error(f"OpenAI API error: {e}")
                return None
            except Exception as e:
                logger.error(f"API call failed: {e}")
                if attempt < max_retries - 1:
                    time.sleep(1)
                    continue
                return None

        return None

    def analyze_property(
        self,
        latitude: float,
        longitude: float,
        satellite_image_url: Optional[str],
        street_image_url: Optional[str] = None,
        street_image_url_2: Optional[str] = None
    ) -> Dict[str, any]:
        """
        Perform comprehensive AI analysis on property imagery using unified multi-image prompt.
        NEW: Supports 3 images (1 satellite + 2 street views from different angles).

        Args:
            latitude: Property latitude
            longitude: Property longitude
            satellite_image_url: URL to satellite imagery (top view)
            street_image_url: URL to first street-level image
            street_image_url_2: URL to second street-level image (different angle)

        Returns:
            Dictionary with all AI analysis results including key insights
        """
        start_time = time.time()

        result = {
            "road_condition": None,
            "power_lines": None,
            "power_lines_street": None,  # Power lines from street view
            "nearby_structures": None,  # Buildings, houses, garages
            "property_condition": None,  # Property-specific analysis
            "nearby_development": None,
            "overall_ai_risk": None,
            "key_insights": [],  # NEW: 2-3 key insights about the property
            "imagery": {  # Store image URLs for frontend display
                "satellite": {
                    "url": satellite_image_url,
                    "source": "Mapbox Satellite"
                } if satellite_image_url else None,
                "street_view_1": {
                    "url": street_image_url,
                    "source": "Google Street View"
                } if street_image_url else None,
                "street_view_2": {
                    "url": street_image_url_2,
                    "source": "Google Street View"
                } if street_image_url_2 else None
            },
            "model_version": self.model_version,
            "processing_time_seconds": 0,
            "error": None
        }

        try:
            # Process images (now receiving base64 URLs directly from imagery service)
            satellite_image = None
            street_image_1 = None
            street_image_2 = None

            if satellite_image_url:
                # Check if it's a base64 data URL
                if satellite_image_url.startswith('data:image'):
                    logger.info("Converting base64 satellite image...")
                    satellite_image = self._base64_to_bytes(satellite_image_url)
                    if satellite_image:
                        logger.info(f"Satellite image ready ({len(satellite_image)} bytes)")
                else:
                    # Fallback: download from regular URL
                    logger.info(f"Downloading satellite image from: {satellite_image_url}")
                    satellite_image = self._download_image(satellite_image_url)
                    if satellite_image:
                        logger.info(f"Satellite image downloaded successfully ({len(satellite_image)} bytes)")

            if street_image_url:
                # Check if it's a base64 data URL
                if street_image_url.startswith('data:image'):
                    logger.info("Converting base64 street image 1...")
                    street_image_1 = self._base64_to_bytes(street_image_url)
                    if street_image_1:
                        logger.info(f"Street image 1 ready ({len(street_image_1)} bytes)")
                else:
                    # Fallback: download from regular URL
                    logger.info(f"Downloading street view image 1 from: {street_image_url}")
                    street_image_1 = self._download_image(street_image_url)
                    if street_image_1:
                        logger.info(f"Street image 1 downloaded successfully ({len(street_image_1)} bytes)")

            if street_image_url_2:
                # Check if it's a base64 data URL
                if street_image_url_2.startswith('data:image'):
                    logger.info("Converting base64 street image 2...")
                    street_image_2 = self._base64_to_bytes(street_image_url_2)
                    if street_image_2:
                        logger.info(f"Street image 2 ready ({len(street_image_2)} bytes)")
                else:
                    # Fallback: download from regular URL
                    logger.info(f"Downloading street view image 2 from: {street_image_url_2}")
                    street_image_2 = self._download_image(street_image_url_2)
                    if street_image_2:
                        logger.info(f"Street image 2 downloaded successfully ({len(street_image_2)} bytes)")

            # NEW: UNIFIED 3-IMAGE ANALYSIS (single API call with all 3 images)
            if satellite_image and street_image_1 and street_image_2:
                logger.info("ðŸš€ Running UNIFIED 3-IMAGE analysis (1 satellite + 2 street views in one prompt)...")
                unified_analysis = self._analyze_all_images_unified(
                    satellite_image, street_image_1, street_image_2, latitude, longitude
                )

                # Extract all components from unified analysis
                result["power_lines"] = unified_analysis.get("power_lines", {})
                result["power_lines_street"] = unified_analysis.get("power_lines_street", {})
                result["road_condition"] = unified_analysis.get("road_condition", {})
                result["nearby_structures"] = unified_analysis.get("nearby_structures", {})
                result["property_condition"] = unified_analysis.get("property_condition", {})
                result["nearby_development"] = unified_analysis.get("nearby_development", {})
                result["key_insights"] = unified_analysis.get("key_insights", [])

                logger.info(f"âœ… Unified 3-image analysis complete - extracted {len(result['key_insights'])} key insights")
            elif satellite_image and street_image_1:
                # Fallback to 2-image analysis
                logger.info("ðŸš€ Running 2-IMAGE analysis (1 satellite + 1 street view)...")
                unified_analysis = self._analyze_two_images_unified(
                    satellite_image, street_image_1, latitude, longitude
                )

                # Extract all components from unified analysis
                result["power_lines"] = unified_analysis.get("power_lines", {})
                result["power_lines_street"] = unified_analysis.get("power_lines_street", {})
                result["road_condition"] = unified_analysis.get("road_condition", {})
                result["nearby_structures"] = unified_analysis.get("nearby_structures", {})
                result["property_condition"] = unified_analysis.get("property_condition", {})
                result["nearby_development"] = unified_analysis.get("nearby_development", {})
                result["key_insights"] = unified_analysis.get("key_insights", [])

                logger.info(f"âœ… Unified 2-image analysis complete - extracted {len(result['key_insights'])} key insights")
            else:
                # FALLBACK: Use existing individual analysis methods
                logger.warning("âš ï¸  Not all images available, using fallback individual analysis...")

                # PRIORITY 1: Satellite analysis (power lines + road + development combined)
                if satellite_image:
                    logger.info("ðŸ›°ï¸  Analyzing satellite image (power lines + road + development)...")
                    satellite_analysis = self._detect_power_lines_comprehensive(
                        satellite_image, latitude, longitude
                    )
                    result["power_lines"] = satellite_analysis

                    # Extract road condition from satellite if available
                    satellite_road = satellite_analysis.get('satellite_road_condition')
                    if satellite_road and satellite_road.get('type'):
                        logger.info(f"   ðŸ“ Road condition from satellite: {satellite_road.get('type')}")

                    # Extract development info from satellite if available
                    satellite_dev = satellite_analysis.get('satellite_development')
                    if satellite_dev:
                        logger.info(f"   ðŸ˜ï¸  Development from satellite: {satellite_dev.get('structure_count')} structures")

                # PRIORITY 2: Street view analysis (power lines + road condition combined)
                if street_image:
                    logger.info("ðŸ“¸ Analyzing street view (power lines + road condition)...")
                    street_analysis = self._detect_power_lines_street_view(street_image)
                    result["power_lines_street"] = street_analysis

                    # Extract road condition from street view
                    street_road = street_analysis.get('road_condition_detected')

                    # COMBINE road condition from BOTH sources (street view takes priority)
                    if street_road and street_road.get('type'):
                        result["road_condition"] = street_road
                        logger.info(f"   âœ… Using STREET VIEW road condition: {street_road.get('type')}")

                        # Add satellite road data as additional context if available
                        if satellite_road and satellite_road.get('type'):
                            result["road_condition"]["satellite_confirms"] = satellite_road.get('type')
                            logger.info(f"   ðŸ“¡ Satellite confirms: {satellite_road.get('type')}")
                    elif satellite_road and satellite_road.get('type'):
                        # Use satellite road condition if street view didn't detect it
                        result["road_condition"] = satellite_road
                        logger.info(f"   âœ… Using SATELLITE road condition: {satellite_road.get('type')}")
                    else:
                        # Last resort fallback
                        logger.warning("   âš ï¸  Road condition not detected in either image, using fallback...")
                        result["road_condition"] = self._analyze_road_condition(
                            satellite_image, street_image
                        )

                # Analyze nearby structures (buildings, houses, garages)
                if satellite_image:
                    logger.info("Detecting nearby structures...")
                    result["nearby_structures"] = self._detect_nearby_structures(
                        satellite_image
                    )

                # Analyze property condition
                if street_image:
                    logger.info("Analyzing property condition...")
                    result["property_condition"] = self._analyze_property_condition(
                        street_image
                    )

                # Detect nearby development
                if satellite_image:
                    logger.info("Detecting nearby development...")
                    result["nearby_development"] = self._detect_nearby_development(
                        satellite_image
                    )

            # Calculate overall AI risk with enhanced factors
            logger.info("Calculating overall AI risk...")
            result["overall_ai_risk"] = self._calculate_overall_ai_risk(
                result["road_condition"],
                result["power_lines"],
                result["power_lines_street"],
                result["nearby_structures"],
                result["property_condition"],
                result["nearby_development"]
            )

        except Exception as e:
            logger.error(f"AI analysis error: {str(e)}", exc_info=True)
            result["error"] = str(e)

        result["processing_time_seconds"] = time.time() - start_time
        logger.info(f"AI analysis completed in {result['processing_time_seconds']:.2f}s")
        return result

    def _analyze_all_images_unified(
        self,
        satellite_image: bytes,
        street_image_1: bytes,
        street_image_2: bytes,
        latitude: float,
        longitude: float
    ) -> Dict[str, any]:
        """
        NEW: Unified 3-image analysis using single comprehensive prompt.
        Analyzes 1 satellite + 2 street view images together for maximum accuracy.

        Args:
            satellite_image: Satellite image bytes (top view)
            street_image_1: First street view image bytes
            street_image_2: Second street view image bytes (different angle)
            latitude: Property latitude
            longitude: Property longitude

        Returns:
            Comprehensive analysis with all detections and key insights
        """
        import os

        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            logger.error("âŒ No OpenAI API key configured")
            return self._fallback_empty_analysis()

        try:
            # Encode all 3 images to base64
            satellite_b64 = base64.b64encode(satellite_image).decode('utf-8')
            street_b64_1 = base64.b64encode(street_image_1).decode('utf-8')
            street_b64_2 = base64.b64encode(street_image_2).decode('utf-8')

            logger.info(f"ðŸ“¤ Sending 3-image unified analysis request...")

            # COMPREHENSIVE UNIFIED PROMPT - All analysis in one call with 3 images
            prompt = """You are an EXPERT PROPERTY ANALYST specializing in comprehensive property risk assessment using aerial and ground-level imagery analysis.

ðŸŽ¯ **YOUR MISSION**: Perform a DETAILED, THOROUGH analysis of ALL 3 images to provide accurate property assessment covering infrastructure, access, condition, and surroundings.

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ðŸ“¸ **3 IMAGES PROVIDED FOR ANALYSIS**:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**IMAGE 1 - GOOGLE MAPS SATELLITE (TOP VIEW)**:
- Aerial view from directly above showing property boundaries, nearby structures, roads, and overhead features
- Use this for: detecting power line corridors, counting structures, measuring distances, assessing density

**IMAGE 2 - STREET VIEW (DIRECTION 1)**:
- Ground-level view from first camera angle
- Use this for: power poles/lines, road surface quality, property condition, visible infrastructure

**IMAGE 3 - STREET VIEW (DIRECTION 2)**:
- Ground-level view from opposite/different camera angle (180Â° or different heading)
- Use this for: confirming findings from angle 1, detecting infrastructure missed in first view, complete coverage

**ANALYSIS METHODOLOGY**:
âœ“ Examine ALL 3 images carefully before making conclusions
âœ“ Cross-reference findings between images to verify accuracy
âœ“ If something appears in ANY of the 3 images, include it in your analysis
âœ“ Use multiple angles to eliminate blind spots and false negatives
âœ“ Provide specific details about WHAT you see and WHERE (which image)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ðŸ” **ANALYSIS TASKS** (Analyze thoroughly):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

**1. ELECTRICAL INFRASTRUCTURE DETECTION** (TOP PRIORITY):

**IMPORTANT**: Power lines indicate GOOD electrical infrastructure access. Their presence is POSITIVE for development.

**FROM SATELLITE IMAGE (Image 1)**:
- Look for thin dark lines crossing the image (power cables viewed from above)
- Look for small dots in straight-line patterns (utility poles along streets)
- Look for cleared vegetation corridors (power line right-of-way)
- Measure approximate distance from red property marker to nearest visible power infrastructure
- Note: Cables are VERY thin from satellite - look carefully at all streets

**FROM STREET VIEW ANGLE 1 (Image 2)**:
- Scan the TOP HALF of image for overhead wires against the sky
- Look for tall wooden/concrete/metal poles along the street
- Check for transformers (gray cylinders on poles)
- Look for crossbars and insulators on poles
- Identify cable type: overhead distribution lines, thick transmission lines, or service drops to houses
- Determine position: directly_above (over property), in_front_close (on adjacent street), nearby (visible in distance), or far

**FROM STREET VIEW ANGLE 2 (Image 3)**:
- Repeat same detailed scan as Angle 1
- Look for poles or wires that may not be visible in Angle 1
- Confirm or supplement findings from first street view
- **CRITICAL**: If you see power infrastructure in EITHER street view angle, mark as VISIBLE

**CROSS-REFERENCE ALL 3 IMAGES**:
- If poles visible in satellite â†’ there MUST be cables connecting them
- If poles visible in street view â†’ scan satellite to locate them from above
- Combine findings from all 3 angles for complete picture

**2. ROAD SURFACE & ACCESS ASSESSMENT**:

**FROM SATELLITE (Image 1)**:
- Identify road surface type visible from above:
  * PAVED: Dark gray or black, smooth surface, clear edges, may show lane markings
  * GRAVEL: Light gray/tan, rougher texture, less defined edges
  * DIRT: Brown/tan/red earth color, very rough, irregular edges, may show tire tracks
  * POOR: Paved but with visible cracks, patches, or deterioration
- Check road width (narrow vs wide)
- Verify road connects to larger road network

**FROM STREET VIEWS (Images 2 & 3)**:
- Examine road surface at ground level in BOTH angles:
  * Look at immediate foreground and road surface texture
  * Check for asphalt/concrete (paved), gravel stones, or dirt/mud
  * Identify potholes, cracks, or damage
  * Assess maintenance quality (well-maintained vs deteriorating)
- Use the CLEARER view from either angle for final determination
- Cross-check: Does street view match satellite observation?

**3. PROPERTY & SURROUNDING AREA ANALYSIS**:

**FROM SATELLITE (Image 1)**:
- **Count ALL visible structures** in the surrounding area:
  * Houses/residences (rectangular buildings with roofs)
  * Garages, sheds, outbuildings (smaller structures)
  * Driveways and parking areas (light-colored rectangles)
  * Swimming pools (blue rectangles in yards)
  * Commercial/industrial buildings (larger structures)
- **Assess density**: high (many structures close together), medium (scattered), low (few structures), none (no development)
- **Identify area type**: RESIDENTIAL (homes), COMMERCIAL (shops/offices), INDUSTRIAL (warehouses/factories), AGRICULTURAL (farms/fields), UNDEVELOPED (empty land/forest)
- Look at property marked with red pin: Is there a structure on it? What's on adjacent lots?

**FROM STREET VIEWS (Images 2 & 3)**:
- **Property condition** at the photographed location:
  * EXCELLENT: Well-maintained, modern, clean
  * GOOD: Maintained, average condition
  * AVERAGE: Some wear, typical condition
  * POOR: Neglected, damaged, deteriorating
  * VACANT: Empty lot or abandoned structure
  * UNDEVELOPED: Natural vegetation, no improvements
- **Vegetation**: Overgrown/wild vs maintained/cleared vs natural forest
- **Signs of activity**: Lived-in, active use vs abandoned vs construction
- **Surroundings**: Neighboring properties condition, street character
- Combine observations from BOTH street angles for complete assessment

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ðŸ“Š **OUTPUT REQUIREMENTS**:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Respond with ONLY this JSON format (no other text):

{
    "power_lines_street": {
        "visible": true/false,
        "confidence": 0.0-1.0,
        "type": "overhead_lines|utility_poles|transmission_tower|none",
        "position": "directly_above|in_front_close|nearby|far|none",
        "proximity": "very_close|close|moderate|far",
        "details": "Detailed description of what you see from street view"
    },
    "power_lines": {
        "visible": true/false,
        "confidence": 0.0-1.0,
        "distance_meters": number or null,
        "line_type": "transmission|distribution|single|multiple|none",
        "details": "Detailed description of what you see from satellite view"
    },
    "road_condition": {
        "type": "PAVED|GRAVEL|DIRT|POOR|UNKNOWN",
        "confidence": 0.0-1.0,
        "details": "Description combining both satellite and street view observations"
    },
    "nearby_structures": {
        "structures_detected": true/false,
        "count": number,
        "types": ["house", "garage", "shed", etc],
        "density": "high|medium|low|none",
        "confidence": 0.0-1.0,
        "details": "Description of structures visible in satellite view"
    },
    "property_condition": {
        "condition": "EXCELLENT|GOOD|AVERAGE|POOR|VACANT|UNDEVELOPED",
        "maintained": true/false,
        "development_status": "developed|partially_developed|undeveloped",
        "concerns": ["list of concerns if any"],
        "confidence": 0.0-1.0,
        "details": "Description of property condition from street view"
    },
    "nearby_development": {
        "type": "RESIDENTIAL|COMMERCIAL|INDUSTRIAL|AGRICULTURAL|UNDEVELOPED",
        "count": number,
        "confidence": 0.0-1.0,
        "details": "Description of surrounding development from satellite"
    },
    "key_insights": [
        "INSIGHT 1: [State the MOST CRITICAL finding - electrical infrastructure status, access issues, or major concerns. Be specific: 'Power lines visible on adjacent street - excellent utility access' or 'No electrical infrastructure detected - utility installation required']",
        "INSIGHT 2: [Second most important finding - road condition, property condition, or development context. Example: 'Well-maintained paved road with good access' or 'Property in undeveloped area with limited services']",
        "INSIGHT 3: [Third notable observation - surrounding area, density, or other factors affecting value/development. Example: 'Low-density residential area with similar properties' or 'High-density development with nearby amenities']"
    ]
}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âš ï¸ **CRITICAL REQUIREMENTS**:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. **EXAMINE ALL 3 IMAGES THOROUGHLY**:
   - Look at satellite (Image 1), street angle 1 (Image 2), and street angle 2 (Image 3)
   - Do NOT make conclusions based on just 1 or 2 images
   - Use all 3 angles to eliminate blind spots

2. **CROSS-REFERENCE BETWEEN IMAGES**:
   - What you see in satellite should correlate with street views
   - What you see in one street angle should be considered alongside the other angle
   - If infrastructure appears in ANY image, mark as detected

3. **BE DETAILED AND SPECIFIC**:
   - In "details" fields, describe EXACTLY what you observe
   - State WHICH image(s) show the feature: "Visible in Image 2 and 3" or "Detected in satellite (Image 1)"
   - Provide measurements, counts, positions when possible

4. **KEY INSIGHTS MUST BE ACTIONABLE**:
   - Write clear, specific insights a property buyer/developer would need
   - Focus on: electrical access, road quality, area development, property condition
   - Use concrete language: "Power lines on adjacent street within 30m" NOT "Some infrastructure nearby"
   - Highlight both positives (good access) and concerns (missing utilities)

5. **ELECTRICAL INFRASTRUCTURE IS PRIORITY #1**:
   - Check ALL 3 images carefully for poles, wires, cables
   - Remember: Power lines = GOOD (infrastructure access), No power lines = CONCERN (installation needed)
   - Be thorough - missing infrastructure is expensive to install

6. **CONFIDENCE LEVELS**:
   - Set high confidence (0.8-1.0) when features are clearly visible in multiple images
   - Set medium confidence (0.5-0.7) when visible but unclear or in only 1 image
   - Set low confidence (0.1-0.4) when difficult to determine

**NOW BEGIN YOUR ANALYSIS**. Respond with ONLY the JSON object specified above. No additional text before or after the JSON.

            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }

            payload = {
                "model": "gpt-4o",
                "messages": [{
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{satellite_b64}",
                                "detail": "high"
                            }
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{street_b64_1}",
                                "detail": "high"
                            }
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{street_b64_2}",
                                "detail": "high"
                            }
                        }
                    ]
                }],
                "max_tokens": 1500,
                "temperature": 0.2
            }

            logger.info("â³ Calling OpenAI API with unified multi-image prompt...")
            result = self._call_openai_with_retry(
                "https://api.openai.com/v1/chat/completions",
                headers,
                payload
            )

            if not result:
                logger.error("âŒ Unified analysis API call failed")
                return self._fallback_empty_analysis()

            content = result['choices'][0]['message']['content']
            logger.debug(f"ðŸ“¨ Raw unified analysis response: {content[:300]}...")

            # Parse JSON response
            try:
                if "```json" in content:
                    content = content.split("```json")[1].split("```")[0].strip()
                elif "```" in content:
                    content = content.split("```")[1].split("```")[0].strip()

                parsed = json.loads(content)

                # Add source metadata
                if "power_lines" in parsed:
                    parsed["power_lines"]["source"] = "unified_satellite"
                if "power_lines_street" in parsed:
                    parsed["power_lines_street"]["source"] = "unified_street"

                logger.info("âœ… Unified multi-image analysis SUCCESS")
                logger.info(f"   ðŸ”Œ Power lines detected: {parsed.get('power_lines_street', {}).get('visible', False)}")
                logger.info(f"   ðŸ›£ï¸  Road: {parsed.get('road_condition', {}).get('type', 'UNKNOWN')}")
                logger.info(f"   ðŸ˜ï¸  Development: {parsed.get('nearby_development', {}).get('type', 'UNKNOWN')}")
                logger.info(f"   ðŸ’¡ Insights: {len(parsed.get('key_insights', []))} key findings")

                return parsed

            except json.JSONDecodeError as e:
                logger.error(f"Failed to parse unified analysis JSON: {e}")
                logger.error(f"Content was: {content[:500]}")
                return self._fallback_empty_analysis()

        except Exception as e:
            logger.error(f"Unified analysis error: {str(e)}", exc_info=True)
            return self._fallback_empty_analysis()

    def _analyze_two_images_unified(
        self,
        satellite_image: bytes,
        street_image: bytes,
        latitude: float,
        longitude: float
    ) -> Dict[str, any]:
        """
        Fallback: 2-image analysis when only 1 street view is available.
        """
        import os

        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            logger.error("âŒ No OpenAI API key configured")
            return self._fallback_empty_analysis()

        try:
            # Encode images
            satellite_b64 = base64.b64encode(satellite_image).decode('utf-8')
            street_b64 = base64.b64encode(street_image).decode('utf-8')

            # Simplified 2-image prompt (fallback)
            prompt = """Analyze the 2 provided images (satellite + street view) and provide comprehensive property assessment.

Respond with JSON containing: power_lines_street, power_lines, road_condition, nearby_structures, property_condition, nearby_development, and key_insights array.

Be thorough and specific in your analysis."""

            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }

            payload = {
                "model": "gpt-4o",
                "messages": [{
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{satellite_b64}", "detail": "high"}},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{street_b64}", "detail": "high"}}
                    ]
                }],
                "max_tokens": 1500,
                "temperature": 0.2
            }

            result = self._call_openai_with_retry(
                "https://api.openai.com/v1/chat/completions",
                headers,
                payload
            )

            if not result:
                return self._fallback_empty_analysis()

            content = result['choices'][0]['message']['content']

            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()

            parsed = json.loads(content)

            if "power_lines" in parsed:
                parsed["power_lines"]["source"] = "unified_satellite"
            if "power_lines_street" in parsed:
                parsed["power_lines_street"]["source"] = "unified_street"

            return parsed

        except Exception as e:
            logger.error(f"2-image analysis error: {str(e)}", exc_info=True)
            return self._fallback_empty_analysis()

    def _fallback_empty_analysis(self) -> Dict[str, any]:
        """Return empty analysis structure for fallback."""
        return {
            "power_lines": {"visible": False, "confidence": 0.0},
            "power_lines_street": {"visible": False, "confidence": 0.0},
            "road_condition": {"type": "UNKNOWN", "confidence": 0.0},
            "nearby_structures": {"structures_detected": False, "count": 0, "confidence": 0.0},
            "property_condition": {"condition": "UNKNOWN", "confidence": 0.0},
            "nearby_development": {"type": "UNKNOWN", "count": 0, "confidence": 0.0},
            "key_insights": []
        }

    def _base64_to_bytes(self, base64_url: str) -> Optional[bytes]:
        """
        Convert base64 data URL to bytes.

        Args:
            base64_url: Base64 data URL (e.g., data:image/jpeg;base64,...)

        Returns:
            Image bytes or None
        """
        try:
            # Extract base64 data from data URL
            # Format: data:image/jpeg;base64,XXXXXX
            if ',' in base64_url:
                base64_data = base64_url.split(',', 1)[1]
                image_bytes = base64.b64decode(base64_data)
                return image_bytes
            else:
                logger.error("Invalid base64 data URL format")
                return None
        except Exception as e:
            logger.error(f"Failed to decode base64 image: {str(e)}")
            return None

    def _download_image(self, image_url: str) -> Optional[bytes]:
        """
        Download image from URL.

        Args:
            image_url: URL to download

        Returns:
            Image bytes or None
        """
        try:
            response = self.session.get(image_url, timeout=30)
            response.raise_for_status()
            return response.content
        except Exception as e:
            logger.error(f"Failed to download image from {image_url}: {str(e)}")
            return None

    def _analyze_road_condition(
        self,
        satellite_image: Optional[bytes],
        street_image: Optional[bytes]
    ) -> Dict[str, any]:
        """
        Analyze road condition from imagery using AI classification.

        Classification categories:
        - PAVED: Well-maintained paved road
        - DIRT: Unpaved/dirt road
        - GRAVEL: Gravel road
        - POOR: Paved but poor condition
        - UNKNOWN: Unable to determine

        Args:
            satellite_image: Satellite image bytes
            street_image: Street-level image bytes

        Returns:
            Road condition analysis result
        """
        # Prefer street image for road analysis, fallback to satellite
        image_to_analyze = street_image if street_image else satellite_image

        if not image_to_analyze:
            return {
                "type": "UNKNOWN",
                "confidence": 0.0,
                "source": "no_imagery",
                "details": "No imagery available for analysis"
            }

        try:
            # Use computer vision model for road classification
            # For production, this would call a trained model
            # For now, we'll use a mock implementation with OpenAI Vision API as fallback

            result = self._classify_road_with_ai(image_to_analyze)

            return result

        except Exception as e:
            logger.error(f"Road condition analysis failed: {str(e)}")
            return {
                "type": "UNKNOWN",
                "confidence": 0.0,
                "source": "error",
                "details": str(e)
            }

    def _classify_road_with_ai(self, image_bytes: bytes) -> Dict[str, any]:
        """
        Classify road condition using AI vision model.

        This method can be replaced with:
        1. Local PyTorch/TensorFlow model
        2. Cloud AI service (AWS Rekognition, Azure Computer Vision, etc.)
        3. OpenAI Vision API
        4. Custom-trained road classification model

        Args:
            image_bytes: Image data

        Returns:
            Classification result
        """
        import os

        # Try OpenAI Vision API if available
        openai_api_key = os.getenv('OPENAI_API_KEY')

        if openai_api_key:
            try:
                result = self._classify_with_openai_vision(image_bytes, "road")
                return result
            except Exception as e:
                logger.warning(f"OpenAI Vision API failed: {str(e)}")

        # Fallback to heuristic-based classification
        # In production, replace with actual ML model
        logger.info("Using heuristic road classification (no AI model configured)")

        return {
            "type": "PAVED",  # Default assumption
            "confidence": 0.3,  # Low confidence without AI
            "source": "heuristic",
            "details": "AI model not configured, using default classification"
        }

    def _detect_power_lines_comprehensive(
        self,
        satellite_image: bytes,
        latitude: float,
        longitude: float
    ) -> Dict[str, any]:
        """
        Comprehensive power line detection from satellite imagery with verification.

        Args:
            satellite_image: Satellite image bytes
            latitude: Property latitude
            longitude: Property longitude

        Returns:
            Power line detection result with geometry
        """
        if not satellite_image:
            return {
                "visible": False,
                "confidence": 0.0,
                "distance_meters": None,
                "geometry": None,
                "source": "no_imagery"
            }

        try:
            # Use enhanced AI detection for power lines
            result = self._detect_with_ai(satellite_image, "power_lines")

            # If power lines detected, extract geometry
            if result.get("visible", False):
                # Convert detection boxes to GeoJSON geometry
                geometry = self._detections_to_geojson(
                    result.get("detections", []),
                    latitude,
                    longitude
                )

                result["geometry"] = json.dumps(geometry) if geometry else None

            # Log detection results
            logger.info(f"Satellite power line detection: visible={result.get('visible')}, "
                       f"confidence={result.get('confidence', 0):.2f}")

            return result

        except Exception as e:
            logger.error(f"Power line detection failed: {str(e)}")
            return {
                "visible": False,
                "confidence": 0.0,
                "distance_meters": None,
                "geometry": None,
                "source": "error",
                "error": str(e)
            }

    def _detect_power_lines_street_view(self, street_image: bytes) -> Dict[str, any]:
        """
        Detect power lines from street view imagery with improved accuracy.

        Args:
            street_image: Street view image bytes

        Returns:
            Power line detection result with position information
        """
        logger.info("ðŸ” Starting street view power line detection...")

        if not street_image:
            logger.warning("âš ï¸ No street image provided for power line detection")
            return {
                "visible": False,
                "confidence": 0.0,
                "source": "no_imagery"
            }

        logger.debug(f"ðŸ“¸ Street image size: {len(street_image)} bytes")

        try:
            # Use the improved detection module
            from ai_analysis_improved import detect_power_lines_enhanced
            logger.info("ðŸ¤– Using enhanced AI detection module...")
            result = detect_power_lines_enhanced(street_image, "street")

            logger.info(f"âœ… Detection complete - Visible: {result.get('visible')}, Confidence: {result.get('confidence', 0):.2f}")
            if result.get('visible'):
                logger.info(f"   ðŸ“ Position: {result.get('position', 'unknown')}")
                logger.info(f"   ðŸ“Š Type: {result.get('type', 'unknown')}")
                logger.info(f"   ðŸ“ Proximity: {result.get('proximity', 'unknown')}")
                logger.debug(f"   ðŸ“ Details: {result.get('details', 'N/A')[:100]}")

            return result
        except ImportError:
            logger.warning("âš ï¸ Improved detection module not available, using fallback")
            return self._detect_powerlines_street_fallback(street_image)

    def _detect_powerlines_street_fallback(self, street_image: bytes) -> Dict[str, any]:
        """Fallback street view power line detection with position analysis."""
        import os
        logger.info("Using fallback power line detection method...")

        api_key = os.getenv('OPENAI_API_KEY')

        if not api_key:
            logger.error("No OpenAI API key configured")
            return {
                "visible": False,
                "confidence": 0.0,
                "source": "no_api_key"
            }

        image_b64 = base64.b64encode(street_image).decode('utf-8')
        logger.debug(f"Sending image to OpenAI API (base64 length: {len(image_b64)})")

        prompt = """Analyze this Google Street View image for power infrastructure and road condition.

Detect power lines, utility poles, cables, and assess road surface. Respond with JSON containing power_lines and road_condition objects.

IMPORTANT:
- Detect ALL power infrastructure visible (poles, cables, wires, towers)
- Report exact position and proximity
- Be thorough - even thin/faint lines count

Look for power poles, wires, cables. Check road surface type (paved/gravel/dirt).

Respond with JSON:
{
  "power_lines": {"visible": bool, "confidence": float, "position": str, "details": str},
  "road_condition": {"type": str, "confidence": float, "details": str}
}"""

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }

        payload = {
            "model": "gpt-4o",
            "messages": [{
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {
                        "url": f"data:image/jpeg;base64,{image_b64}",
                        "detail": "high"
                    }}
                ]
            }],
            "max_tokens": 400,
            "temperature": 0.1
        }

        logger.info("â³ Calling OpenAI API with retry logic...")
        result = self._call_openai_with_retry(
            "https://api.openai.com/v1/chat/completions",
            headers,
            payload
        )

        if not result:
            logger.error("âŒ OpenAI API call failed after retries")
            return {
                "visible": False,
                "confidence": 0.0,
                "source": "api_failed"
            }

        content = result['choices'][0]['message']['content']
        logger.debug(f"ðŸ“¨ Raw API response: {content[:200]}...")

        try:
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()

            parsed = json.loads(content)

            # Extract power_lines and road_condition from new format
            power_lines_data = parsed.get('power_lines', parsed)  # Fallback to root if old format
            road_condition_data = parsed.get('road_condition', {})

            # Add source
            power_lines_data["source"] = "openai_vision_street"
            power_lines_data["road_condition_detected"] = road_condition_data

            logger.info(f"âœ… Street view analysis SUCCESS")
            logger.info(f"   ðŸ”Œ Power Lines:")
            logger.info(f"      ðŸ‘ï¸  Visible: {power_lines_data.get('visible')}")
            logger.info(f"      ðŸ“Š Confidence: {power_lines_data.get('confidence', 0):.2f}")
            logger.info(f"      ðŸ“ Position: {power_lines_data.get('position', 'unknown')}")
            logger.info(f"      ðŸ“ Proximity: {power_lines_data.get('proximity', 'unknown')}")
            logger.info(f"   ðŸ›£ï¸  Road Condition: {road_condition_data.get('type', 'UNKNOWN')}")
            logger.debug(f"   ðŸ“ Details: {power_lines_data.get('details', 'N/A')[:150]}")

            return power_lines_data
        except json.JSONDecodeError:
            logger.warning("âš ï¸ Failed to parse JSON, using keyword detection fallback")
            content_lower = content.lower()
            visible = any(kw in content_lower for kw in ['power line', 'utility pole', 'overhead', 'wire'])
            logger.info(f"   Keyword detection: visible={visible}")
            return {
                "visible": visible,
                "confidence": 0.4 if visible else 0.1,
                "position": "unknown",
                "source": "openai_vision_street_text",
                "details": content[:200]
            }

    def _detect_nearby_structures(self, satellite_image: bytes) -> Dict[str, any]:
        """
        Detect nearby structures (buildings, houses, garages) from satellite imagery.

        Args:
            satellite_image: Satellite image bytes

        Returns:
            Structure detection result
        """
        if not satellite_image:
            return {
                "structures_detected": False,
                "count": 0,
                "types": [],
                "confidence": 0.0,
                "source": "no_imagery"
            }

        try:
            import os
            api_key = os.getenv('OPENAI_API_KEY')

            if not api_key:
                return self._detect_with_ai(satellite_image, "development")

            image_b64 = base64.b64encode(satellite_image).decode('utf-8')

            prompt = """Analyze this satellite image and identify ALL structures and buildings.

COUNT AND IDENTIFY:
1. **Houses/Residences**: Single-family homes, mobile homes
2. **Buildings**: Commercial buildings, apartments, warehouses
3. **Garages**: Detached garages, carports, sheds
4. **Driveways/Parking**: Paved areas, parking lots
5. **Swimming Pools**: Backyard pools (blue rectangles)
6. **Other Structures**: Barns, outbuildings, etc.

Respond ONLY with JSON:
{
    "structures_detected": true/false,
    "count": total_number,
    "types": ["house", "garage", "shed", etc],
    "density": "high|medium|low|none",
    "nearest_distance_meters": estimated_distance,
    "confidence": 0.0-1.0,
    "details": "detailed description"
}"""

            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }

            payload = {
                "model": "gpt-4o",
                "messages": [{
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_b64}"}}
                    ]
                }],
                "max_tokens": 600,
                "temperature": 0.3
            }

            response = self.session.post(
                "https://api.openai.com/v1/chat/completions",
                headers=headers,
                json=payload,
                timeout=60
            )
            response.raise_for_status()

            result = response.json()
            content = result['choices'][0]['message']['content']

            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()

            parsed = json.loads(content)
            parsed["source"] = "openai_vision"

            logger.info(f"Structure detection: count={parsed.get('count')}, "
                       f"density={parsed.get('density')}, confidence={parsed.get('confidence', 0):.2f}")

            return parsed

        except Exception as e:
            logger.error(f"Structure detection failed: {str(e)}")
            return {
                "structures_detected": False,
                "count": 0,
                "types": [],
                "confidence": 0.0,
                "source": "error",
                "error": str(e)
            }

    def _analyze_property_condition(self, street_image: bytes) -> Dict[str, any]:
        """
        Analyze property condition from street view.

        Args:
            street_image: Street view image bytes

        Returns:
            Property condition analysis
        """
        if not street_image:
            return {
                "condition": "UNKNOWN",
                "confidence": 0.0,
                "source": "no_imagery"
            }

        try:
            import os
            api_key = os.getenv('OPENAI_API_KEY')

            if not api_key:
                return {
                    "condition": "UNKNOWN",
                    "confidence": 0.0,
                    "source": "no_api_key"
                }

            image_b64 = base64.b64encode(street_image).decode('utf-8')

            prompt = """Analyze this street view image and assess the property/area condition.

EVALUATE:
1. **Property Appearance**: Well-maintained, average, poor, vacant
2. **Vegetation**: Overgrown, maintained, cleared, natural
3. **Infrastructure**: Roads, sidewalks, curbs condition
4. **Surroundings**: Neighbors, general area upkeep
5. **Signs of Activity**: Lived-in, abandoned, under development

Respond ONLY with JSON:
{
    "condition": "EXCELLENT|GOOD|AVERAGE|POOR|VACANT|UNDEVELOPED",
    "maintained": true/false,
    "development_status": "developed|partially_developed|undeveloped",
    "concerns": ["list", "of", "concerns"],
    "confidence": 0.0-1.0,
    "details": "description"
}"""

            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }

            payload = {
                "model": "gpt-4o",
                "messages": [{
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_b64}"}}
                    ]
                }],
                "max_tokens": 500,
                "temperature": 0.3
            }

            response = self.session.post(
                "https://api.openai.com/v1/chat/completions",
                headers=headers,
                json=payload,
                timeout=60
            )
            response.raise_for_status()

            result = response.json()
            content = result['choices'][0]['message']['content']

            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()

            parsed = json.loads(content)
            parsed["source"] = "openai_vision"

            logger.info(f"Property condition: {parsed.get('condition')}, "
                       f"maintained={parsed.get('maintained')}, confidence={parsed.get('confidence', 0):.2f}")

            return parsed

        except Exception as e:
            logger.error(f"Property condition analysis failed: {str(e)}")
            return {
                "condition": "UNKNOWN",
                "confidence": 0.0,
                "source": "error",
                "error": str(e)
            }

    def _detect_with_ai(
        self,
        image_bytes: bytes,
        detection_type: str
    ) -> Dict[str, any]:
        """
        Perform object detection using AI model.

        Args:
            image_bytes: Image data
            detection_type: Type of detection ('power_lines', 'development')

        Returns:
            Detection result
        """
        import os

        openai_api_key = os.getenv('OPENAI_API_KEY')

        if openai_api_key:
            try:
                if detection_type == "power_lines":
                    return self._detect_powerlines_with_openai(image_bytes)
                elif detection_type == "development":
                    return self._detect_development_with_openai(image_bytes)
            except Exception as e:
                logger.warning(f"OpenAI detection failed: {str(e)}")

        # Fallback to basic detection
        logger.info(f"Using heuristic {detection_type} detection (no AI model configured)")

        if detection_type == "power_lines":
            return {
                "visible": False,
                "confidence": 0.1,
                "distance_meters": None,
                "detections": [],
                "source": "heuristic"
            }
        elif detection_type == "development":
            return {
                "type": "UNKNOWN",
                "count": 0,
                "confidence": 0.1,
                "source": "heuristic"
            }

    def _classify_with_openai_vision(
        self,
        image_bytes: bytes,
        classification_type: str
    ) -> Dict[str, any]:
        """
        Use OpenAI Vision API for image classification.

        Args:
            image_bytes: Image data
            classification_type: 'road' or other type

        Returns:
            Classification result
        """
        import os

        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            raise ValueError("OPENAI_API_KEY not configured")

        # Encode image to base64
        image_b64 = base64.b64encode(image_bytes).decode('utf-8')

        if classification_type == "road":
            prompt = """Analyze this image and classify the road condition.
            Respond with ONLY a JSON object in this exact format:
            {"type": "PAVED|DIRT|GRAVEL|POOR|UNKNOWN", "confidence": 0.0-1.0, "details": "brief description"}

            Classification guide:
            - PAVED: Well-maintained asphalt or concrete road
            - DIRT: Unpaved dirt road
            - GRAVEL: Gravel surface
            - POOR: Paved but with significant damage/deterioration
            - UNKNOWN: Cannot determine from image
            """
        else:
            prompt = "Analyze this property image and describe what you see."

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }

        payload = {
            "model": "gpt-4o",
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": prompt
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_b64}"
                            }
                        }
                    ]
                }
            ],
            "max_tokens": 300
        }

        response = self.session.post(
            "https://api.openai.com/v1/chat/completions",
            headers=headers,
            json=payload,
            timeout=60
        )
        response.raise_for_status()

        result = response.json()
        content = result['choices'][0]['message']['content']

        # Parse JSON response
        try:
            # Extract JSON from response (handle markdown code blocks)
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()

            parsed = json.loads(content)
            parsed["source"] = "openai_vision"
            return parsed
        except json.JSONDecodeError:
            logger.warning(f"Failed to parse OpenAI response as JSON: {content}")
            return {
                "type": "UNKNOWN",
                "confidence": 0.0,
                "source": "openai_vision",
                "details": content
            }

    def _detect_powerlines_with_openai(self, image_bytes: bytes) -> Dict[str, any]:
        """Detect power lines using OpenAI Vision API with improved accuracy and rate limiting."""
        try:
            # Use the improved detection module
            from ai_analysis_improved import detect_power_lines_enhanced
            result = detect_power_lines_enhanced(image_bytes, "satellite")
            result["detections"] = []  # Add for compatibility
            return result
        except ImportError:
            logger.warning("Improved detection not available, using fallback")
            return self._detect_powerlines_fallback(image_bytes)

    def _detect_powerlines_fallback(self, image_bytes: bytes) -> Dict[str, any]:
        """Fallback power line detection - simplified version."""
        logger.info("Using simplified fallback for power line detection")
        return {
            "visible": False,
            "confidence": 0.5,
            "distance_meters": None,
            "detections": [],
            "source": "fallback_simplified"
        }

    def _detect_powerlines_fallback_OLD_UNUSED(self, image_bytes: bytes) -> Dict[str, any]:
        """OLD UNUSED - Disabled old fallback method."""
        return {
            "visible": False,
            "confidence": 0.0,
            "distance_meters": None,
            "detections": [],
            "source": "disabled_old_method"
        }

    def _old_disabled_method(self):
        """Old method disabled - emoji syntax errors."""
        return {"visible": False, "confidence": 0.0}

    def _old_prompt_content_disabled(self):
        """Old prompt removed."""
        # Old method disabled - was causing syntax errors with emojis
        return None

        payload = {
            "model": "gpt-4o",
            "messages": [{
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {
                        "url": f"data:image/jpeg;base64,{image_b64}",
                        "detail": "high"
                    }}
                ]
            }],
            "max_tokens": 400,
            "temperature": 0.1
        }

        # Use the retry method
        result = self._call_openai_with_retry(
            "https://api.openai.com/v1/chat/completions",
            headers,
            payload
        )

        if not result:
            return {
                "visible": False,
                "confidence": 0.0,
                "distance_meters": None,
                "detections": [],
                "source": "api_failed"
            }

        content = result['choices'][0]['message']['content']

        try:
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()

            parsed = json.loads(content)

            # Extract power_lines, road_condition, and development from new combined format
            power_lines_data = parsed.get('power_lines', parsed)  # Fallback to root if old format
            road_condition_data = parsed.get('road_condition', {})
            development_data = parsed.get('development', {})

            # Add metadata
            power_lines_data["source"] = "openai_vision_satellite"
            power_lines_data["detections"] = []
            power_lines_data["satellite_road_condition"] = road_condition_data
            power_lines_data["satellite_development"] = development_data

            logger.info(f"âœ… Satellite analysis SUCCESS")
            logger.info(f"   ðŸ”Œ Power Lines: visible={power_lines_data.get('visible')}, "
                       f"confidence={power_lines_data.get('confidence', 0):.2f}, "
                       f"distance={power_lines_data.get('distance_meters')}m")
            logger.info(f"   ðŸ›£ï¸  Road (satellite): {road_condition_data.get('type', 'UNKNOWN')}")
            logger.info(f"   ðŸ˜ï¸  Development: {development_data.get('structure_count', 0)} structures, "
                       f"density={development_data.get('density', 'unknown')}")

            return power_lines_data
        except json.JSONDecodeError:
            logger.warning(f"JSON parse failed, using keyword detection")
            content_lower = content.lower()
            visible = any(kw in content_lower for kw in [
                'power line', 'powerline', 'transmission', 'utility pole', 'tower', 'wire'
            ])

            return {
                "visible": visible,
                "confidence": 0.5 if visible else 0.0,
                "distance_meters": None,
                "detections": [],
                "source": "openai_vision_text",
                "details": content[:200]
            }

    def _detect_development_with_openai(self, image_bytes: bytes) -> Dict[str, any]:
        """Detect nearby development using OpenAI Vision API."""
        import os

        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            raise ValueError("OPENAI_API_KEY not configured")

        image_b64 = base64.b64encode(image_bytes).decode('utf-8')

        prompt = """Analyze this satellite image for nearby development and structures.
        Respond with ONLY a JSON object in this exact format:
        {"type": "RESIDENTIAL|COMMERCIAL|INDUSTRIAL|AGRICULTURAL|UNDEVELOPED", "count": number, "confidence": 0.0-1.0, "details": "description"}

        Guidelines:
        - Identify dominant development type in the area
        - Count visible structures/buildings
        - Provide confidence in assessment
        """

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }

        payload = {
            "model": "gpt-4o",
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {"url": f"data:image/jpeg;base64,{image_b64}"}
                        }
                    ]
                }
            ],
            "max_tokens": 300
        }

        response = self.session.post(
            "https://api.openai.com/v1/chat/completions",
            headers=headers,
            json=payload,
            timeout=60
        )
        response.raise_for_status()

        result = response.json()
        content = result['choices'][0]['message']['content']

        try:
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()

            parsed = json.loads(content)
            parsed["source"] = "openai_vision"
            return parsed
        except json.JSONDecodeError:
            logger.warning(f"Failed to parse OpenAI development response: {content}")
            return {
                "type": "UNKNOWN",
                "count": 0,
                "confidence": 0.0,
                "source": "openai_vision"
            }

    def _detect_nearby_development(self, satellite_image: bytes) -> Dict[str, any]:
        """
        Detect nearby development from satellite imagery.

        Args:
            satellite_image: Satellite image bytes

        Returns:
            Development detection result
        """
        if not satellite_image:
            return {
                "type": "UNKNOWN",
                "count": 0,
                "confidence": 0.0,
                "source": "no_imagery"
            }

        try:
            result = self._detect_with_ai(satellite_image, "development")
            return result
        except Exception as e:
            logger.error(f"Development detection failed: {str(e)}")
            return {
                "type": "UNKNOWN",
                "count": 0,
                "confidence": 0.0,
                "source": "error",
                "error": str(e)
            }

    def _detections_to_geojson(
        self,
        detections: List[Dict],
        center_lat: float,
        center_lon: float
    ) -> Optional[Dict]:
        """
        Convert detection bounding boxes to GeoJSON geometry.

        Args:
            detections: List of detection dictionaries with bounding boxes
            center_lat: Center latitude of image
            center_lon: Center longitude of image

        Returns:
            GeoJSON FeatureCollection or None
        """
        if not detections:
            return None

        features = []

        for detection in detections:
            # Each detection should have: bbox, confidence, class
            bbox = detection.get('bbox')
            if not bbox:
                continue

            # Convert pixel coordinates to lat/lon (approximate)
            # This is a simplified conversion; in production, use proper projection
            x1, y1, x2, y2 = bbox

            # Approximate meters per pixel at this latitude
            meters_per_pixel = 0.3  # Depends on zoom level and latitude

            # Convert to offset in degrees
            lon1 = center_lon + ((x1 - 400) * meters_per_pixel / 111320)
            lat1 = center_lat - ((y1 - 300) * meters_per_pixel / 110540)
            lon2 = center_lon + ((x2 - 400) * meters_per_pixel / 111320)
            lat2 = center_lat - ((y2 - 300) * meters_per_pixel / 110540)

            feature = {
                "type": "Feature",
                "geometry": {
                    "type": "Polygon",
                    "coordinates": [[
                        [lon1, lat1],
                        [lon2, lat1],
                        [lon2, lat2],
                        [lon1, lat2],
                        [lon1, lat1]
                    ]]
                },
                "properties": {
                    "confidence": detection.get('confidence', 0.0),
                    "class": detection.get('class', 'power_line')
                }
            }
            features.append(feature)

        return {
            "type": "FeatureCollection",
            "features": features
        }

    def _calculate_overall_ai_risk(
        self,
        road_condition: Optional[Dict],
        power_lines: Optional[Dict],
        power_lines_street: Optional[Dict],
        nearby_structures: Optional[Dict],
        property_condition: Optional[Dict],
        nearby_development: Optional[Dict]
    ) -> Dict[str, any]:
        """
        Calculate comprehensive AI-based risk assessment.

        PRIORITY RISK FACTORS (highest to lowest):
        1. POWER LINES - Top priority, major safety/insurability concern
        2. Property condition - Poor maintenance indicates risk
        3. Road condition - Access issues
        4. Nearby structures - Isolation/density concerns
        5. Development type - Area characteristics

        Args:
            road_condition: Road condition analysis
            power_lines: Power line detection (satellite)
            power_lines_street: Power line detection (street view)
            nearby_structures: Structure detection
            property_condition: Property condition analysis
            nearby_development: Development detection

        Returns:
            Comprehensive risk assessment
        """
        risk_score = 0.0
        confidence_scores = []
        risk_factors = []

        logger.info("="*60)
        logger.info("CALCULATING AI RISK ASSESSMENT")
        logger.info("="*60)

        # PRIORITY 1: POWER LINES (HIGHEST RISK - TOP OF THE LINE)
        power_line_detected = False
        max_power_confidence = 0.0

        # Check satellite power lines (for informational purposes - position matters more)
        if power_lines and power_lines.get('visible', False):
            power_line_detected = True
            pl_conf = power_lines.get('confidence', 0.0)
            distance = power_lines.get('distance_meters')
            max_power_confidence = pl_conf

            # Satellite detection confirms power infrastructure exists (GOOD)
            logger.info(f"ðŸ›°ï¸  Satellite confirms power lines visible, distance={distance}m, confidence={pl_conf:.2f}")

            # Don't add/subtract risk here - street view position is more accurate
            # Just log the information for reference

            confidence_scores.append(pl_conf)

        # Check street view power lines with POSITION-BASED RISK SCORING
        if power_lines_street and power_lines_street.get('visible', False):
            power_line_detected = True
            pl_street_conf = power_lines_street.get('confidence', 0.0)
            pl_type = power_lines_street.get('type', 'unknown')
            proximity = power_lines_street.get('proximity', 'unknown')
            position = power_lines_street.get('position', 'unknown')

            max_power_confidence = max(max_power_confidence, pl_street_conf)

            logger.info(f"ðŸ”Œ Street view power lines detected:")
            logger.info(f"   ðŸ“ Position: {position}")
            logger.info(f"   ðŸ“ Proximity: {proximity}")
            logger.info(f"   ðŸ“Š Type: {pl_type}")
            logger.info(f"   ðŸŽ¯ Confidence: {pl_street_conf:.2f}")

            # NEW POWER LINE RISK LOGIC - INFRASTRUCTURE ACCESS PERSPECTIVE:
            # Power lines PRESENT = POSITIVE (good electrical infrastructure access)
            # Power lines TOO CLOSE = RISK (safety hazard only if directly overhead)
            # NO power lines = NEGATIVE (no infrastructure, may need expensive electrical installation)

            if position == 'directly_above' or proximity == 'very_close':
                # Lines directly overhead - Safety hazard BUT infrastructure exists
                risk_score += 15  # Only moderate risk (safety concern exists but infrastructure present)
                risk_factors.append('âš ï¸ Power lines directly overhead - Safety clearance required but electrical infrastructure available')
                logger.warning(f"âš ï¸ Power lines overhead (position={position}, proximity={proximity}, confidence={pl_street_conf:.2f}) +15 risk")

            elif position == 'in_front_close' or position == 'nearby' or proximity == 'close':
                # Lines nearby - IDEAL SITUATION (good access, no safety issues)
                risk_score -= 10  # REDUCES risk (good infrastructure access)
                risk_factors.append('âœ… POSITIVE: Power lines nearby - Excellent electrical infrastructure access, easy utility connection')
                logger.info(f"âœ… POSITIVE: Power lines nearby (position={position}, proximity={proximity}, confidence={pl_street_conf:.2f}) -10 risk")

            elif position == 'far' or proximity == 'moderate' or proximity == 'far':
                # Lines visible but distant - OK (infrastructure exists in area)
                risk_score += 0  # Neutral (infrastructure exists but may need extension)
                risk_factors.append('ðŸŸ¡ Power lines visible at distance - Electrical infrastructure exists in area')
                logger.info(f"ðŸŸ¡ Power lines far (position={position}, proximity={proximity}) - neutral (0 risk)")

            else:
                # Unknown position - assume accessible
                risk_score -= 5  # Slight positive (infrastructure detected)
                risk_factors.append('âœ… Power infrastructure detected - Electrical access available')
                logger.info(f"âœ… Power lines detected, good infrastructure (position={position}, proximity={proximity}) -5 risk")

            confidence_scores.append(pl_street_conf)

        if power_line_detected:
            logger.info(f"âœ… POWER INFRASTRUCTURE DETECTED - Max confidence: {max_power_confidence:.2f}")
        else:
            # NO POWER LINES = NEGATIVE (NO INFRASTRUCTURE - expensive to install)
            risk_score += 20  # INCREASES risk (no electrical infrastructure, costly installation)
            risk_factors.append('âš ï¸ CONCERN: No power lines detected - No electrical infrastructure visible, may require expensive utility installation')
            logger.info("âš ï¸ NO POWER LINES DETECTED - Missing infrastructure (+20 risk)")

        # PRIORITY 2: Property Condition
        if property_condition:
            prop_cond = property_condition.get('condition', 'UNKNOWN')
            prop_conf = property_condition.get('confidence', 0.0)
            concerns = property_condition.get('concerns', [])

            if prop_cond == 'POOR' or prop_cond == 'VACANT':
                risk_score += 25
                risk_factors.append(f'Poor property condition: {prop_cond}')
                logger.info(f"Property condition: {prop_cond} (+25 risk)")
            elif prop_cond == 'UNDEVELOPED':
                risk_score += 20
                risk_factors.append('Undeveloped property')
                logger.info(f"Property condition: UNDEVELOPED (+20 risk)")
            elif prop_cond == 'AVERAGE':
                risk_score += 5
                logger.info(f"Property condition: AVERAGE (+5 risk)")

            if concerns:
                risk_score += len(concerns) * 3
                risk_factors.append(f'{len(concerns)} concerns identified: {", ".join(concerns[:3])}')
                logger.info(f"Property concerns: {concerns}")

            confidence_scores.append(prop_conf)

        # PRIORITY 3: Road Condition
        if road_condition:
            road_type = road_condition.get('type', 'UNKNOWN')
            road_conf = road_condition.get('confidence', 0.0)

            if road_type == 'DIRT':
                risk_score += 20
                risk_factors.append('Unpaved/dirt road access')
                logger.info("Road condition: DIRT (+20 risk)")
            elif road_type == 'GRAVEL':
                risk_score += 15
                risk_factors.append('Gravel road access')
                logger.info("Road condition: GRAVEL (+15 risk)")
            elif road_type == 'POOR':
                risk_score += 18
                risk_factors.append('Poor road condition')
                logger.info("Road condition: POOR (+18 risk)")

            confidence_scores.append(road_conf)

        # PRIORITY 4: Nearby Structures
        if nearby_structures:
            struct_count = nearby_structures.get('count', 0)
            density = nearby_structures.get('density', 'unknown')
            struct_conf = nearby_structures.get('confidence', 0.0)

            if density == 'none' or struct_count == 0:
                risk_score += 15
                risk_factors.append('Isolated - no nearby structures')
                logger.info("Structure density: NONE (+15 risk)")
            elif density == 'low' or struct_count <= 2:
                risk_score += 10
                risk_factors.append('Low density - few nearby structures')
                logger.info(f"Structure density: LOW (count={struct_count}) (+10 risk)")
            else:
                logger.info(f"Structure density: {density} (count={struct_count}) - no additional risk")

            confidence_scores.append(struct_conf)

        # PRIORITY 5: Development Type (isolation)
        if nearby_development:
            dev_type = nearby_development.get('type', 'UNKNOWN')
            dev_count = nearby_development.get('count', 0)
            dev_conf = nearby_development.get('confidence', 0.0)

            if dev_type == 'UNDEVELOPED' or dev_count == 0:
                risk_score += 12
                risk_factors.append('Remote/undeveloped area')
                logger.info("Development: UNDEVELOPED (+12 risk)")
            elif dev_type == 'INDUSTRIAL':
                risk_score += 10
                risk_factors.append('Industrial area')
                logger.info("Development: INDUSTRIAL (+10 risk)")

            confidence_scores.append(dev_conf)

        # Calculate overall confidence
        overall_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0.0

        # Determine risk level with power line priority
        if risk_score >= 60:
            risk_level = "HIGH"
        elif risk_score >= 30:
            risk_level = "MEDIUM"
        else:
            risk_level = "LOW"

        logger.info("="*60)
        logger.info(f"FINAL AI RISK ASSESSMENT: {risk_level}")
        logger.info(f"Total Risk Score: {risk_score}")
        logger.info(f"Overall Confidence: {overall_confidence:.2f}")
        logger.info(f"Risk Factors ({len(risk_factors)}): {risk_factors}")
        logger.info("="*60)

        return {
            "level": risk_level,
            "score": risk_score,
            "confidence": overall_confidence,
            "factors": risk_factors,
            "power_lines_detected": power_line_detected,
            "power_line_confidence": max_power_confidence
        }

    def check_and_determine_road_access_override(
        self,
        road_condition: Optional[Dict],
        gis_road_access: bool,
        gis_road_distance: float
    ) -> Dict[str, any]:
        """
        Determine if AI analysis should override GIS road access results.

        If AI detects poor/no road from imagery but GIS says there's access,
        or vice versa, determine which source to trust based on confidence.

        Args:
            road_condition: AI road condition analysis
            gis_road_access: GIS-detected road access (True/False)
            gis_road_distance: Distance to nearest road in meters

        Returns:
            Dict with override decision and updated values
        """
        should_override = False
        new_road_access = gis_road_access
        new_road_distance = gis_road_distance
        override_reason = None

        if not road_condition:
            return {
                "should_override": False,
                "new_road_access": gis_road_access,
                "new_road_distance": gis_road_distance,
                "reason": "No AI road analysis available"
            }

        road_type = road_condition.get('type', 'UNKNOWN')
        confidence = road_condition.get('confidence', 0.0)

        # High confidence AI detection should override low-confidence GIS
        if confidence >= 0.6:  # AI is confident
            # AI sees DIRT/GRAVEL but GIS says no access - AI is seeing unpaved road
            if road_type in ['DIRT', 'GRAVEL'] and not gis_road_access:
                should_override = True
                new_road_access = True
                new_road_distance = 50  # Estimate close proximity
                override_reason = f"AI detected {road_type} road (confidence: {confidence:.2f}) but GIS found no road access. Updated to reflect unpaved road access."

            # AI sees PAVED road but GIS says no access - GIS likely missed it
            elif road_type == 'PAVED' and not gis_road_access:
                should_override = True
                new_road_access = True
                new_road_distance = 30  # Close proximity assumed
                override_reason = f"AI detected PAVED road (confidence: {confidence:.2f}) but GIS found no road access. Updated to reflect road access."

            # AI sees no road/unknown but GIS says there's close access - trust GIS for now
            # (GIS is more accurate for geographic road network data)
            elif road_type == 'UNKNOWN' and gis_road_access and gis_road_distance > 100:
                # If GIS says road is far and AI can't see it, might be landlocked
                should_override = True
                new_road_access = False
                new_road_distance = gis_road_distance
                override_reason = f"AI cannot confirm road access and GIS shows road is {gis_road_distance:.0f}m away. Updated to no direct access."

        return {
            "should_override": should_override,
            "new_road_access": new_road_access,
            "new_road_distance": new_road_distance,
            "reason": override_reason
        }
